---
title: "group_proj"
author: "kaike"
date: "April 18, 2020"
output: html_document
---

<<<<<<< HEAD
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# import libraries
library(car)
library(lmtest)
#library(sandwich) # for robust test (when heteroskedasticity occurs)
library(dplyr) # dataframe
library(ggplot2)
library(gmodels) # Crosstable
library(class) # knn
library(neuralnet) # ANN
library(kernlab) #SVM
library(C50) # decision tree

# read data file
housing <- read.csv("california-housing-prices.csv")
str(housing)
summary(housing)

plot(median_house_value, longitude)
plot(median_house_value, latitude)
plot(median_house_value, housing_median_age)
plot(median_house_value, total_rooms)
plot(median_house_value, total_bedrooms)
plot(median_house_value, population)
plot(median_house_value, households)
plot(median_house_value, median_income)
plot(median_house_value, ocean_proximity)
```

```{r}
#housing$total_bedrooms <- ifelse(is.na(housing$total_bedrooms), mean(housing$total_bedrooms, na.rm = TRUE), housing$total_bedrooms)


#lm with every variables
model_lin1 <- lm(median_house_value ~., data = housing)
summary(model_lin1)

#add interaction term of longtitude*latitude -> similar to pointing the location on the map
model_lin2 <- lm(median_house_value ~. + longitude*latitude, data = housing)
summary(model_lin2)
#housing$resi <- model_lin2$residuals
#varfunc_ols <- lm(log(resi^2) ~ log(longitude) + log(latitude) + log(housing_median_age) + #log(total_rooms) + log(total_bedrooms) + log(population) + log(households) + log(median_income) + #ocean_proximity + log(longitude*latitude), data = housing)
#housing$varfunc <- exp(varfunc_ols$fitted.values)
#model_glin2 <- lm(median_house_value ~ . + longitude*latitude, weights = 1/sqrt(varfunc), data = food)


#add functional form
model_lin3 <- lm(log(median_house_value) ~ longitude + latitude + I(housing_median_age^2) + total_rooms + total_bedrooms + population + households + log(median_income) + ocean_proximity, data = housing)
summary(model_lin3) #R-squared = 0.6725

#drop some variable with high collinearity
#drop total_bedroom
model_lin4 <- lm(log(median_house_value) ~ longitude + latitude + I(housing_median_age^2) + total_rooms + population + households + log(median_income) + ocean_proximity, data = housing)
summary(model_lin4) #R-squared = 0.6705
#drop household
model_lin5 <- lm(log(median_house_value) ~ longitude + latitude + I(housing_median_age^2) + total_rooms + total_bedrooms + population + log(median_income) + ocean_proximity, data = housing)
summary(model_lin5) #R-squared = 0.6713
#drop both
model_lin6 <- lm(log(median_house_value) ~ longitude + latitude + I(housing_median_age^2) + total_rooms + population + log(median_income) + ocean_proximity, data = housing)
summary(model_lin6) #R-squared = 0.6584
#For model4 and model5, after dropping one variable made the VIF dropped significantly



#check how the models performed
#shapiro.test(residuals(model_lin1)) #see if the residuals are normally distributed.

#test homoskedasticity
bptest(model_lin1) #if p-value is smaller than the significance level we choose, we reject the null
                   #hypothesis, meaning there exist heteroskedasticity
#The result is that we reject the null hypothesis, i.e. there exist heteroskedasticity

#test collinearity
vif(model_lin5) #if the value is greater than 10 then it's very likely to have multicollinearity
                #actually if the value is greater than 5 is worth noticing.
#The largest VIF here is total_bedroom and households (around 6), so we can consider dropping them

#test autocorrelation of residual
dwtest(model_lin1) #if p-value is smaller than the significance level, we reject the null hypoth.,
                   #meanig there is autocorrelation (or the model is incorrectly specified)
#We reject the null hypothesis, so there is autocorrelation.

#test if there are outliers
outlierTest(model_lin1)
#There are two significant outliers, we can consider dropping them

#plots
plot(model_lin1, which=1) #residual and fitted value plot
plot(model_lin1, which=2)



```


<<<<<<< HEAD
=======
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

=======
>>>>>>> 205da1173a7f525bfabdccc368fc885fc7759024
```{r}
# import libraries
library(car)
library(lmtest)
library(dplyr) # dataframe
library(ggplot2)
library(gmodels) # Crosstable
library(class) # knn
library(neuralnet) # ANN
library(kernlab) #SVM
library(C50) # decision tree

# read data file
housing <- read.csv("california-housing-prices.csv")
str(housing)
summary(housing)

housing_train <- housing[1:16000,]
housing_test <- housing[16001:20640,]


```

```{r}
#clean data

housing$total_bedrooms <- ifelse(is.na(housing$total_bedrooms), mean(housing$total_bedrooms, na.rm = TRUE)/mean(housing$total_rooms, na.rm = TRUE)*housing$total_rooms, housing$total_bedrooms)

```

## linear regression

```{r}
model_lin <- lm(median_house_value ~., data = housing)
summary(model_lin)

```

<<<<<<< HEAD
>>>>>>> a7aa94061e57198dec18f6430fbc2178085173cb
=======
## SVM

```{r}
# Data categorization
hist(housing$median_house_value)

Pricecut <- function(x) {
  if (x <100000) {
    pricecat <- "below100K"
  } else if (x >=100000 & x < 200000) {
    pricecat <- "100k-200k"
  } else if (x >=200000 & x < 300000) {
    pricecat <- "200k-300k"
  } else if (x >=300000 & x < 400000) {
    pricecat <- "300k-400k"
  } else if (x >=400000 & x < 500000) {
    pricecat <- "400k-500k"
  } else {
    pricecat <- "over500k"
  }
}

# creat new data with categorization "housingcat"
housingcat <- housing
housingcat$pricecat <- sapply(housingcat$median_house_value, FUN = Pricecut)
housingcat$pricecat <- as.factor(housingcat$pricecat)
str(housingcat)

# train & test data for "housing cat"
housingcat_train <- housingcat[1:16000,]
housingcat_test <- housingcat[16001:20640,]

# SVM1 - vanilladot - housevalue
model_svm1 <- ksvm(median_house_value ~., data = housingcat_train,
             kernel = "vanilladot")

svm1_result <- predict(model_svm1, housingcat_test)

plot(svm1_result, housingcat_test$median_house_value)
cor_svm1 <- cor(svm1_result, housingcat_test$median_house_value); cor_svm1

# SVM1_2 - vanilladot - Pricecat
model_svm1_2 <- ksvm(pricecat ~., data = housingcat_train,
             kernel = "vanilladot")

svm1_2_result <- predict(model_svm1_2, housingcat_test)

aggreement1_2 <- svm1_2_result == housingcat_test$pricecat

table(svm1_2_result,housingcat_test$pricecat)
agrmt_svm1_2 <- prop.table(table(aggreement1_2)); agrmt_svm1_2

# SVM2 - rbfdot - housevalue
model_svm2 <- ksvm(median_house_value ~., data = housingcat_train,
             kernel = "rbfdot")

svm2_result <- predict(model_svm2, housingcat_test)

plot(svm2_result, housingcat_test$median_house_value)
cor_svm2 <- cor(svm2_result, housingcat_test$median_house_value); cor_svm2

# SVM2_2 - rbfdot - Pricecat
model_svm2_2 <- ksvm(pricecat ~., data = housingcat_train,
             kernel = "rbfdot")

svm2_2_result <- predict(model_svm2_2, housingcat_test)

aggreement2_2 <- svm2_2_result == housingcat_test$pricecat

table(svm2_2_result,housingcat_test$pricecat)
agrmt_svm2_2 <- prop.table(table(aggreement2_2)); agrmt_svm2_2


```
## Decision Tree
```{r}
# random suffling
set.seed(33)
housingcat_train_rand <- housingcat_train[order(runif(16000)), ]

# Decision Tree model
model_DT <- C5.0(pricecat ~., data = housingcat_train_rand)
DT_pred <- predict(model_DT, housingcat_test)

aggreement_DT <- DT_pred == housingcat_test$pricecat

table(DT_pred,housingcat_test$pricecat)
agrmt_DT <- prop.table(table(aggreement_DT)); agrmt_DT


```
##ANN
```{r}
normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}
#str(hou)
hou <- housing[-10]
hou$ocean_proximity <- as.numeric(housing$ocean_proximity)
housing_norm <- as.data.frame(lapply(hou, normalize))
#housing_norm$median_house_value <- housing$median_house_value
str(housing_norm)
housing_norm_train <- housing_norm[1:16000,]
housing_norm_test <- housing_norm[16001:20640,]

housing_model <- neuralnet(formula = median_house_value ~.,
                              data = housing_norm_train,hidden = c(4,3,2),threshold = 0.08,stepmax = 8e+04,lifesign =  "full",lifesign.step= 1000,act.fct = "logistic")
#plot(housing_model)

# obtain model results
model_results <- compute(housing_model, housing_norm_test[-10])
# obtain predicted strength values
predicted_median_house_value <- model_results$net.result
# examine the correlation between predicted and actual values
prediction_h<- as.data.frame(predicted_median_house_value)
#str(prediction_h)
cor(prediction_h$V1, housing_norm_test$median_house_value)

```

>>>>>>> 205da1173a7f525bfabdccc368fc885fc7759024

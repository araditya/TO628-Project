---
title: "group_proj"
author: "kaike"
date: "April 18, 2020"
output: html_document
---

<<<<<<< HEAD
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



<<<<<<< HEAD
=======
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

=======
>>>>>>> 205da1173a7f525bfabdccc368fc885fc7759024


#=============================================================================
# Importing libraries
#=============================================================================
```{r}
# import libraries
library(car)
library(lmtest)
library(dplyr) # dataframe
library(ggplot2)
library(gmodels) # Crosstable
library(class) # knn
library(neuralnet) # ANN
library(kernlab) #SVM
library(C50) # decision tree
library(caret) #partitioning
library(randomForest) #randomforest
```


#=============================================================================
# Initial data setup
#=============================================================================
```{r}
# read data file
housing <- read.csv("california-housing-prices.csv")
str(housing) #'ocean_proximity' column is factor
summary(housing)
colnames(housing)[colSums(is.na(housing)) > 0] #total bedroom column has n/a

#clean the dataset
housing$total_bedrooms <- ifelse(is.na(housing$total_bedrooms), mean(housing$total_bedrooms, na.rm = TRUE)/mean(housing$total_rooms, na.rm = TRUE)*housing$total_rooms, housing$total_bedrooms) #fill n/a of 'total_bedrooms' column in a fixed proportion to firgures in 'total_rooms'
housing <- housing[,c(9,1:8,10)] #move 'median_house_value' column to first

```

#=============================================================================
# Linear regression
#=============================================================================
```{r}
# Graphs of median_house_value with other explanatory variables
plot(housing$median_house_value, housing$longitude)
plot(housing$median_house_value, housing$latitude)
plot(housing$median_house_value, housing$housing_median_age)
plot(housing$median_house_value, housing$total_rooms)
plot(housing$median_house_value, housing$total_bedrooms)
plot(housing$median_house_value, housing$population)
plot(housing$median_house_value, housing$households)
plot(housing$median_house_value, housing$median_income)
plot(housing$median_house_value, housing$ocean_proximity)

#separate the dataset
in_train <- createDataPartition(housing$median_house_value, p = 0.8, list = FALSE)
housing_train <- housing[in_train,]
housing_test <- housing[in_train,]

# Linear model with every variable
model_lin1 <- lm(median_house_value ~., data = housing_train)
summary(model_lin1) #R-squared = 0.6244

# Test collinearity
vif(model_lin1) #if the value is greater than 10 then it's very likely to have multicollinearity
                #actually if the value is greater than 5 is worth noticing.
#The largest VIF here is total_bedroom and households (around 6)


# Add interaction term of longtitude*latitude => similar to pointing the location on the map
model_lin2 <- lm(median_house_value ~. + longitude*latitude, data = housing_train)
summary(model_lin2) #R-squared = 0.6293

model_lin2_2 <- lm(median_house_value ~. + housing_median_age*ocean_proximity, data = housing_train)
summary(model_lin2_2) #R-squared = 0.6273

model_lin2_3 <- lm(median_house_value ~. + housing_median_age*ocean_proximity + longitude*latitude, data = housing_train)
summary(model_lin2_3) #R-squared = 0.6324

model_lin2_2_2 <- lm(median_house_value ~ longitude + latitude + housing_median_age + total_rooms + total_bedrooms + population + households + median_income + ocean_proximity + housing_median_age*ocean_proximity + latitude*ocean_proximity + total_rooms*ocean_proximity, data = housing_train)
summary(model_lin2_2_2)


# Add functional form
model_lin3 <- lm(log(median_house_value) ~ longitude + latitude + housing_median_age + I(housing_median_age^2) + total_rooms + total_bedrooms + population + households + log(median_income) + ocean_proximity + housing_median_age*ocean_proximity + longitude*latitude, data = housing_train)
summary(model_lin3) #R-squared = 0.6556

# Drop some variable with high collinearity
# Drop total_bedroom
model_lin4 <- lm(log(median_house_value) ~ longitude + latitude + housing_median_age + I(housing_median_age^2) + total_rooms + population + households + log(median_income) + ocean_proximity + housing_median_age*ocean_proximity + longitude*latitude, data = housing_train)
summary(model_lin4) #R-squared = 0.6531
# Drop household
model_lin5 <- lm(log(median_house_value) ~ longitude + latitude + housing_median_age + I(housing_median_age^2) + total_rooms + total_bedrooms + population + log(median_income) + ocean_proximity + housing_median_age*ocean_proximity + longitude*latitude, data = housing_train)
summary(model_lin5) #R-squared = 0.6548
# Drop both
model_lin6 <- lm(log(median_house_value) ~ longitude + latitude + housing_median_age + I(housing_median_age^2) + total_rooms + population + log(median_income) + ocean_proximity + housing_median_age*ocean_proximity + longitude*latitude, data = housing_train)
summary(model_lin6) #R-squared = 0.6386
#For model4 and model5, after dropping one variable made the VIF dropped significantly

#Predict
house_price_prediction <- predict(model_lin2_2_2, newdata = housing_test, type = "response")
prediction_lin <- as.data.frame(house_price_prediction)
cor(prediction_lin, housing_test$median_house_value)

```

<<<<<<< HEAD
>>>>>>> a7aa94061e57198dec18f6430fbc2178085173cb
=======

#=============================================================================
# SVM
#=============================================================================
```{r}
# Data categorization
hist(housing$median_house_value)

Pricecut <- function(x) {
  if (x <100000) {
    pricecat <- "below100K"
  } else if (x >=100000 & x < 200000) {
    pricecat <- "100k-200k"
  } else if (x >=200000 & x < 300000) {
    pricecat <- "200k-300k"
  } else if (x >=300000 & x < 400000) {
    pricecat <- "300k-400k"
  } else if (x >=400000 & x < 500000) {
    pricecat <- "400k-500k"
  } else {
    pricecat <- "over500k"
  }
}

# creat new data with categorization "housingcat"
housingcat <- housing
housingcat$pricecat <- sapply(housingcat$median_house_value, FUN = Pricecut)
housingcat$pricecat <- as.factor(housingcat$pricecat)
housingcat= subset(housingcat, select = -c(median_house_value)) #drop 'median_house_value' from new 'housingcat' data frame
str(housingcat)

# train & test data
in_train <- createDataPartition(housing$median_house_value, p = 0.8, list = FALSE)
housing_train <- housing[in_train,]
housing_test <- housing[-in_train,]

in_train <- createDataPartition(housingcat$pricecat, p = 0.8, list = FALSE)
housingcat_train <- housingcat[in_train,]
housingcat_test <- housingcat[-in_train,]

# SVM1_1: housevalue_vanilladot 
model_svm1_1 <- ksvm(median_house_value ~., data = housing_train, kernel = "vanilladot")
svm1_1_result <- predict(model_svm1_1, housing_test)
plot(svm1_1_result, housing_test$median_house_value)
cor_svm1_1 <- cor(svm1_1_result, housing_test$median_house_value); cor_svm1_1
# Correlation: 0.803

# SVM1_2: housevalue_rbfdot
model_svm1_2 <- ksvm(median_house_value ~., data = housing_train, kernel = "rbfdot")
svm1_2_result <- predict(model_svm1_2, housing_test)
plot(svm1_2_result, housingcat_test$median_house_value)
cor_svm1_2 <- cor(svm1_2_result, housing_test$median_house_value); cor_svm1_2
# Correlation: 0.884

# SVM2_1: Pricecat_vanilladot 
model_svm2_1 <- ksvm(pricecat ~., data = housingcat_train,kernel = "vanilladot")
svm2_1_result <- predict(model_svm2_1, housingcat_test)
aggreement2_1 <- svm2_1_result == housingcat_test$pricecat
table(svm2_1_result,housingcat_test$pricecat)
agrmt_svm2_1 <- prop.table(table(aggreement2_1)); agrmt_svm2_1
# Agreement: 0.624

# SVM2_2: Pricecat_rbfdot
model_svm2_2 <- ksvm(pricecat ~., data = housingcat_train, kernel = "rbfdot")
svm2_2_result <- predict(model_svm2_2, housingcat_test)
aggreement2_2 <- svm2_2_result == housingcat_test$pricecat
table(svm2_2_result,housingcat_test$pricecat)
agrmt_svm2_2 <- prop.table(table(aggreement2_2)); agrmt_svm2_2
# Agreement: 0.662

```

#=============================================================================
# Decision tree & Random forest
#=============================================================================
```{r}
# random suffling
set.seed(33)
housingcat_train_rand <- housingcat_train[order(runif(16513)), ]

# Decision Tree model
model_DT <- C5.0(pricecat ~., data = housingcat_train_rand)
DT_pred <- predict(model_DT, housingcat_test)

aggreement_DT <- DT_pred == housingcat_test$pricecat

table(DT_pred,housingcat_test$pricecat)
agrmt_DT <- prop.table(table(aggreement_DT)); agrmt_DT
# Agreement: 0.662

library(randomForest)
set.seed(300)
model_rf <- randomForest(pricecat ~., data = housingcat_train_rand)
model_rf

rf_pred <- predict(model_rf, housingcat_test)

aggreement_rf <- rf_pred == housingcat_test$pricecat

table(rf_pred, housingcat_test$pricecat)
agrmt_rf <- prop.table(table(aggreement_rf)); agrmt_rf
# Agreement: 0.713

```

#=============================================================================
# ANN
#=============================================================================
```{r}
#normalize
housing_ann <- housing
housing_ann$ocean_proximity <-c(housing_ann$ocean_proximity) #make 'ocean_proximity'dummy variables for machine learning algorithm
normalize <- function(x){return((x-min(x)) / (max(x) - min(x)))}
housing_ann_n <- housing_ann
housing_ann_n[c(2:10)]<- as.data.frame(lapply(housing_ann[c(2:10)], normalize)) #normalize except for 'median_house_value'

#separate data
in_train <- createDataPartition(housing_ann_n$median_house_value, p = 0.8, list = FALSE)
housing_ann_n_train <- housing_ann_n[in_train,]
housing_ann_n_test <- housing_ann_n[-in_train,]

model_ann <- neuralnet(formula = median_house_value ~., data = housing_ann_n_train,hidden = c(4,3,2),threshold = 0.08,stepmax = 8e+04,lifesign =  "full",lifesign.step= 1000,act.fct = "logistic")

ann_result <- compute(model_ann, housing_ann_n_test)
ann_pred <- ann_result$net.result
prediction_h<- as.data.frame(ann_pred)
cor(prediction_h$V1, housing_ann_n_test$median_house_value)

```

#=============================================================================
# KNN
#=============================================================================

```{r}

#normalize
normalize <- function(x){return((x-min(x)) / (max(x) - min(x)))}
housingcat_n <- housingcat
housingcat_n$ocean_proximity <- c(housingcat_n$ocean_proximity) #make 'ocean_proximity'dummy variables
housingcat_n[c(1:9)]<- as.data.frame(lapply(housingcat_n[c(1:9)], normalize))

#separate data
in_train <- createDataPartition(housingcat_n$pricecat, p = 0.8, list = FALSE)
housingcat_n_train <- housingcat_n[in_train,1:9]
housingcat_n_test <- housingcat_n[-in_train,1:9]
housingcat_n_train_labels <- housingcat_n[in_train,10]
housingcat_n_test_labels <- housingcat_n[-in_train,10]

knn_pred <- knn(train = housingcat_n_train, test = housingcat_n_test, cl = housingcat_n_train_labels, k=21)
aggreement_knn <- knn_pred == housingcat_n_test$pricecat
agrmt_knn <- prop.table(table(aggreement_knn)); agrmt_rf
# Agreement: 0.713

```



## Archive

## SVM2
```{r}
library(gtools)
library(kernlab)

#data loading
housing <- read.csv("california-housing-prices.csv")
str(housing)
summary(housing)
colnames(housing)[colSums(is.na(housing)) > 0] #'total_bedrooms' column has N/A

#data cleansing and modification
housing$total_bedrooms <- ifelse(is.na(housing$total_bedrooms), mean(housing$total_bedrooms, na.rm = TRUE)/mean(housing$total_rooms, na.rm = TRUE)*housing$total_rooms, housing$total_bedrooms)
housing$ocean_proximity <- c(housing$ocean_proximity)
housing$price_level <- as.integer(quantcut(housing$median_house_value, q=5, na.rm = TRUE))
housing$price_level <- as.factor(housing$price_level)

#rescale the data
normalize <- function(x){return((x-min(x)) / (max(x) - min(x)))}
housing_n <- housing
housing_n[c(3:9)] <- as.data.frame(lapply(housing[c(3:9)], normalize))

#create SVM model 1 (house category)
in_train <- createDataPartition(housing$median_house_value, p = 0.8, list = FALSE)
housing_n_train <- housing_n[in_train,]
housing_n_test <- housing_n[-in_train,]
svm_model1 <- ksvm(price_level ~ ., data = housing_n_train, kernel = "vanilladot")
svm_test_pred1 <- predict(svm_model1, housing_n_test) 
table(svm_test_pred1, housing_n_test$price_level)

#create SVM model 2 (house value)
housing_n_train <- housing_n[in_train,-11]
housing_n_test <- housing_n[-in_train,-11]
svm_model2 <- ksvm(median_house_value ~ ., data = housing_n_train, kernel = "vanilladot")
svm_test_pred2 <- predict(svm_model2, housing_n_test) 
cor(svm_test_pred2, housing_n_test$median_house_value)
```

# ANN
```{r}
normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}
#str(hou)
hou <- housing[-10]
hou$ocean_proximity <- as.numeric(housing$ocean_proximity)
housing_norm <- as.data.frame(lapply(hou, normalize))
#housing_norm$median_house_value <- housing$median_house_value
str(housing_norm)
housing_norm_train <- housing_norm[1:16000,]
housing_norm_test <- housing_norm[16001:20640,]

housing_model <- neuralnet(formula = median_house_value ~.,
                              data = housing_norm_train,hidden = c(4,3,2),threshold = 0.08,stepmax = 8e+04,lifesign =  "full",lifesign.step= 1000,act.fct = "logistic")
#plot(housing_model)

# obtain model results
model_results <- compute(housing_model, housing_norm_test[-10])
# obtain predicted strength values
predicted_median_house_value <- model_results$net.result
# examine the correlation between predicted and actual values
prediction_h<- as.data.frame(predicted_median_house_value)
#str(prediction_h)
cor(prediction_h$V1, housing_norm_test$median_house_value)

```

# KNN
```{r}
library(class)

normalize <- function(x){return((x-min(x)) / (max(x) - min(x)))}
housing_n <- housing
housing_n[c(1:9)] <- as.data.frame(lapply(housing[c(1:9)], normalize))
housing_train <- housing_n[4001:20640, ]
housing_test <- housing_n[1:4000, ]
housing_train_labels <- housing_n[4001:20640, 1]
housing_test_labels <- housing_n[1:4001, 1]

housing_test_pred <- knn(train = housing_train, test = housing_test,
                      cl = housing_train_labels, k=21)
# Partioning Data Randomly
in_train <- createDataPartition(housing$median_house_value, p = 0.8, list = TRUE)
housing_train <- housing_n[in_train, ]
housing_test <- housing_n[-in_train, ]
housing_train_labels <- housing_n[in_train, 1]
housing_test_labels <- housing_n[-in_train, 1]
housing_test_pred <- knn(train = housing_train, test = housing_test,
                      cl = housing_train_labels, k=21)
```

#rescale the dataset
normalize <- function(x){return((x-min(x)) / (max(x) - min(x)))}
housing_ml_n <- housing_ml
housing_ml_n[c(2:10)]<- as.data.frame(lapply(housing_ml[c(2:10)], normalize)) #normalize against abilities only



housing_ml_train <- housing_ml[in_train,]
housing_ml_test <- housing_ml[in_train,]
housing_ml_n_train <- housing_ml_n[in_train,]
housing_ml_n_test <- housing_ml_n[-in_train,]
housing_ml_n_train_wo_labels <- housing_ml_n[in_train,2:10]
housing_ml_n_test_wo_labels <- housing_ml_n[-in_train,2:10]
train_labels <- housing_ml_n[in_train,1]
test_labels <- housing_ml_n[-in_train,1]


>>>>>>> 205da1173a7f525bfabdccc368fc885fc7759024
